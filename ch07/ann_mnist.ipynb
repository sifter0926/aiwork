{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'  # matplotlib.pyplot 사용 커널 충돌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train=datasets.MNIST('MNIST_data', \n",
    "                           train=True,\n",
    "                           download=True,\n",
    "                           transform=transforms.Compose([transforms.ToTensor]))\n",
    "\n",
    "\n",
    "mnist_test=datasets.MNIST('MNIST_data', \n",
    "                           train=False,\n",
    "                           download=True,\n",
    "                           transform=transforms.Compose([transforms.ToTensor]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: MNIST_data\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               <class 'torchvision.transforms.transforms.ToTensor'>\n",
      "           )\n",
      "Dataset MNIST\n",
      "    Number of datapoints: 10000\n",
      "    Root location: MNIST_data\n",
      "    Split: Test\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               <class 'torchvision.transforms.transforms.ToTensor'>\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "print(mnist_train)\n",
    "print(mnist_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(x):\n",
    "    img=(np.array(x.detach(), dtype='float')).reshape(28,28)\n",
    "    plt.imshow(img, cmap='grey')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaEAAAGdCAYAAAC7EMwUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAZ7ElEQVR4nO3df0zU9x3H8dfVH+cvuIYq3DGREKdpVwxb1amk/twkktTU2ibWLgv+4+z8kVg0Zs5ssqWRzkxjGqbLmoZpVjv/qDoTTSuLgi7OhRpMnbUGJxY6JURq7xAtTP3sD+PFKxT9nne+OXg+km9S7r4fv2+//erTLweHzznnBACAgSesBwAA9F9ECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmBloPcA33blzR5cvX1ZaWpp8Pp/1OAAAj5xzamtrU3Z2tp54oud7nV4XocuXLysnJ8d6DADAI2pqatLo0aN73KfXfTouLS3NegQAQAI8zN/nSYvQ9u3blZeXpyFDhmjixIk6fvz4Q63jU3AA0Dc8zN/nSYnQnj17tHr1am3YsEF1dXWaPn26iouL1djYmIzDAQBSlC8Z76I9ZcoUPffcc9qxY0f0sWeeeUYLFixQeXl5j2sjkYgCgUCiRwIAPGbhcFjp6ek97pPwO6HOzk6dOnVKRUVFMY8XFRXpxIkTXfbv6OhQJBKJ2QAA/UPCI3T16lXdvn1bWVlZMY9nZWWpubm5y/7l5eUKBALRja+MA4D+I2lfmPDNF6Scc92+SLV+/XqFw+Ho1tTUlKyRAAC9TMK/T2jkyJEaMGBAl7uelpaWLndHkuT3++X3+xM9BgAgBST8Tmjw4MGaOHGiqqqqYh6vqqpSYWFhog8HAEhhSXnHhNLSUv30pz/VpEmTNG3aNP3pT39SY2OjXn/99WQcDgCQopISoUWLFqm1tVW//e1vdeXKFeXn5+vQoUPKzc1NxuEAACkqKd8n9Cj4PiEA6BtMvk8IAICHRYQAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwMtB4ASIbvfe97ca174YUXPK/52c9+5nlNbW2t5zV1dXWe18Rr27Ztntd0dnYmfhD0edwJAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmfM45Zz3E/SKRiAKBgPUY6EWWLVvmec3vf//7uI41YsSIuNb1NXPmzPG85ujRo0mYBKksHA4rPT29x324EwIAmCFCAAAzCY9QWVmZfD5fzBYMBhN9GABAH5CUH2r37LPP6u9//3v04wEDBiTjMACAFJeUCA0cOJC7HwDAAyXlNaH6+nplZ2crLy9Pr776qi5evPit+3Z0dCgSicRsAID+IeERmjJlinbt2qWPPvpI77zzjpqbm1VYWKjW1tZu9y8vL1cgEIhuOTk5iR4JANBLJTxCxcXFevnllzVhwgT9+Mc/1sGDByVJO3fu7Hb/9evXKxwOR7empqZEjwQA6KWS8prQ/YYPH64JEyaovr6+2+f9fr/8fn+yxwAA9EJJ/z6hjo4OnTt3TqFQKNmHAgCkmIRHaO3ataqpqVFDQ4P+9a9/6ZVXXlEkElFJSUmiDwUASHEJ/3TcF198ocWLF+vq1asaNWqUpk6dqpMnTyo3NzfRhwIApDjewBS9XkZGhuc1586di+tYmZmZca3ra7766ivPaxYtWuR5zeHDhz2vQergDUwBAL0aEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGAm6T/UDnhUX375pec1GzdujOtYW7Zs8bxm2LBhntc0NjZ6XjNmzBjPa+L15JNPel4zb948z2t4A1NwJwQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzPuecsx7ifpFIRIFAwHoM9FOnT5/2vKagoMDzmn//+9+e1+Tn53te8ziNHTvW85qLFy8mYRL0FuFwWOnp6T3uw50QAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGBmoPUAQG/y5ptvel6zYcMGz2u+//3ve17T2w0ePNh6BKQg7oQAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADM+55yzHuJ+kUhEgUDAegzgoQWDQc9rDh8+7HnNhAkTPK95nD744APPa1555ZUkTILeIhwOKz09vcd9uBMCAJghQgAAM54jdOzYMc2fP1/Z2dny+Xzav39/zPPOOZWVlSk7O1tDhw7VrFmzdPbs2UTNCwDoQzxHqL29XQUFBaqoqOj2+c2bN2vr1q2qqKhQbW2tgsGg5s6dq7a2tkceFgDQt3j+yarFxcUqLi7u9jnnnLZt26YNGzZo4cKFkqSdO3cqKytLu3fv1rJlyx5tWgBAn5LQ14QaGhrU3NysoqKi6GN+v18zZ87UiRMnul3T0dGhSCQSswEA+oeERqi5uVmSlJWVFfN4VlZW9LlvKi8vVyAQiG45OTmJHAkA0Isl5avjfD5fzMfOuS6P3bN+/XqFw+Ho1tTUlIyRAAC9kOfXhHpy75v2mpubFQqFoo+3tLR0uTu6x+/3y+/3J3IMAECKSOidUF5enoLBoKqqqqKPdXZ2qqamRoWFhYk8FACgD/B8J3T9+nVduHAh+nFDQ4NOnz6tjIwMjRkzRqtXr9amTZs0btw4jRs3Tps2bdKwYcP02muvJXRwAEDq8xyhjz/+WLNnz45+XFpaKkkqKSnRn//8Z61bt043b97U8uXLde3aNU2ZMkWHDx9WWlpa4qYGAPQJvIEpcJ+f/OQnntcUFBR4XrN27VrPa77ti3t6izfeeMPzmm3btiV+EPQavIEpAKBXI0IAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgJmE/mRVIBmefvppz2v27dsX17G++93vel4zcCB/jCTpwIED1iMgBXEnBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCY4Z0X0es988wzntfk5eXFdSzejDR+b7zxhuc1q1atSsIkSCXcCQEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZni3RvR6+/bt87xm3bp1cR3rd7/7nec1Q4YMietYfU0oFLIeASmIOyEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAxvYIo+6e23345rXX19vec1Tz75ZFzH8mrgQO9/XCsqKuI6Vnp6elzrAK+4EwIAmCFCAAAzniN07NgxzZ8/X9nZ2fL5fNq/f3/M80uWLJHP54vZpk6dmqh5AQB9iOcItbe3q6CgoMfPNc+bN09XrlyJbocOHXqkIQEAfZPnVzqLi4tVXFzc4z5+v1/BYDDuoQAA/UNSXhOqrq5WZmamxo8fr6VLl6qlpeVb9+3o6FAkEonZAAD9Q8IjVFxcrPfee09HjhzRli1bVFtbqzlz5qijo6Pb/cvLyxUIBKJbTk5OokcCAPRSCf8+oUWLFkX/Oz8/X5MmTVJubq4OHjyohQsXdtl//fr1Ki0tjX4ciUQIEQD0E0n/ZtVQKKTc3Nxv/SZAv98vv9+f7DEAAL1Q0r9PqLW1VU1NTQqFQsk+FAAgxXi+E7p+/bouXLgQ/bihoUGnT59WRkaGMjIyVFZWppdfflmhUEiXLl3SL3/5S40cOVIvvfRSQgcHAKQ+zxH6+OOPNXv27OjH917PKSkp0Y4dO3TmzBnt2rVLX331lUKhkGbPnq09e/YoLS0tcVMDAPoEn3POWQ9xv0gkokAgYD0G0Ov4fD7Pa8rKyuI61q9//WvPa/7zn/94XvOjH/3I85rPP//c8xrYCIfDD3wzXN47DgBghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaS/pNVASTG4MGDPa+J592w4/W///3P85rbt28nYRKkEu6EAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzvIEpkCLefPNN6xF69O6773pe88UXXyRhEqQS7oQAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADM+55yzHuJ+kUhEgUDAeoyU9dRTT3leU1lZGdex3n///ceypi8KhUKe13z22Wee16Snp3teE6+xY8d6XnPx4sUkTILeIhwOP/Aa5E4IAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADAz0HoAJNbbb7/tec38+fPjOtb48eM9r7l8+bLnNf/97389r7lw4YLnNZI0ceJEz2viOQ/r1q3zvOZxvhnpli1bPK+J5/8twJ0QAMAMEQIAmPEUofLyck2ePFlpaWnKzMzUggULdP78+Zh9nHMqKytTdna2hg4dqlmzZuns2bMJHRoA0Dd4ilBNTY1WrFihkydPqqqqSrdu3VJRUZHa29uj+2zevFlbt25VRUWFamtrFQwGNXfuXLW1tSV8eABAavP0hQkffvhhzMeVlZXKzMzUqVOnNGPGDDnntG3bNm3YsEELFy6UJO3cuVNZWVnavXu3li1blrjJAQAp75FeEwqHw5KkjIwMSVJDQ4Oam5tVVFQU3cfv92vmzJk6ceJEt79GR0eHIpFIzAYA6B/ijpBzTqWlpXr++eeVn58vSWpubpYkZWVlxeyblZUVfe6bysvLFQgEoltOTk68IwEAUkzcEVq5cqU++eQTvf/++12e8/l8MR8757o8ds/69esVDoejW1NTU7wjAQBSTFzfrLpq1SodOHBAx44d0+jRo6OPB4NBSXfviEKhUPTxlpaWLndH9/j9fvn9/njGAACkOE93Qs45rVy5Unv37tWRI0eUl5cX83xeXp6CwaCqqqqij3V2dqqmpkaFhYWJmRgA0Gd4uhNasWKFdu/erb/97W9KS0uLvs4TCAQ0dOhQ+Xw+rV69Wps2bdK4ceM0btw4bdq0ScOGDdNrr72WlN8AACB1eYrQjh07JEmzZs2KebyyslJLliyRdPc9sW7evKnly5fr2rVrmjJlig4fPqy0tLSEDAwA6Dt8zjlnPcT9IpGIAoGA9Rgpa+rUqZ7XbN26Na5jTZs2La51Xl26dMnzmk8//TSuY02fPt3zmsf1D6x4/qh+9tlncR1r8uTJntfc/03rgHT323ge9Ma7vHccAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzPAu2tCWLVviWnfhwgXPa7Zv3x7XsSB9+eWXntc89dRTSZgEeDi8izYAoFcjQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwMtB4A9tasWRPXOr/f73nNiBEj4jqWVz/4wQ/iWrd48eIET9K9cDjsec3cuXOTMAlgizshAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMCMzznnrIe4XyQSUSAQsB4DAPCIwuGw0tPTe9yHOyEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABgxlOEysvLNXnyZKWlpSkzM1MLFizQ+fPnY/ZZsmSJfD5fzDZ16tSEDg0A6Bs8RaimpkYrVqzQyZMnVVVVpVu3bqmoqEjt7e0x+82bN09XrlyJbocOHUro0ACAvmGgl50//PDDmI8rKyuVmZmpU6dOacaMGdHH/X6/gsFgYiYEAPRZj/SaUDgcliRlZGTEPF5dXa3MzEyNHz9eS5cuVUtLy7f+Gh0dHYpEIjEbAKB/8DnnXDwLnXN68cUXde3aNR0/fjz6+J49ezRixAjl5uaqoaFBv/rVr3Tr1i2dOnVKfr+/y69TVlam3/zmN/H/DgAAvVI4HFZ6enrPO7k4LV++3OXm5rqmpqYe97t8+bIbNGiQ++CDD7p9/uuvv3bhcDi6NTU1OUlsbGxsbCm+hcPhB7bE02tC96xatUoHDhzQsWPHNHr06B73DYVCys3NVX19fbfP+/3+bu+QAAB9n6cIOee0atUq7du3T9XV1crLy3vgmtbWVjU1NSkUCsU9JACgb/L0hQkrVqzQX/7yF+3evVtpaWlqbm5Wc3Ozbt68KUm6fv261q5dq3/+85+6dOmSqqurNX/+fI0cOVIvvfRSUn4DAIAU5uV1IH3L5/0qKyudc87duHHDFRUVuVGjRrlBgwa5MWPGuJKSEtfY2PjQxwiHw+afx2RjY2Nje/TtYV4Tivur45IlEokoEAhYjwEAeEQP89VxvHccAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMBMr4uQc856BABAAjzM3+e9LkJtbW3WIwAAEuBh/j73uV5263Hnzh1dvnxZaWlp8vl8Mc9FIhHl5OSoqalJ6enpRhPa4zzcxXm4i/NwF+fhrt5wHpxzamtrU3Z2tp54oud7nYGPaaaH9sQTT2j06NE97pOent6vL7J7OA93cR7u4jzcxXm4y/o8BAKBh9qv1306DgDQfxAhAICZlIqQ3+/Xxo0b5ff7rUcxxXm4i/NwF+fhLs7DXal2HnrdFyYAAPqPlLoTAgD0LUQIAGCGCAEAzBAhAICZlIrQ9u3blZeXpyFDhmjixIk6fvy49UiPVVlZmXw+X8wWDAatx0q6Y8eOaf78+crOzpbP59P+/ftjnnfOqaysTNnZ2Ro6dKhmzZqls2fP2gybRA86D0uWLOlyfUydOtVm2CQpLy/X5MmTlZaWpszMTC1YsEDnz5+P2ac/XA8Pcx5S5XpImQjt2bNHq1ev1oYNG1RXV6fp06eruLhYjY2N1qM9Vs8++6yuXLkS3c6cOWM9UtK1t7eroKBAFRUV3T6/efNmbd26VRUVFaqtrVUwGNTcuXP73PsQPug8SNK8efNiro9Dhw49xgmTr6amRitWrNDJkydVVVWlW7duqaioSO3t7dF9+sP18DDnQUqR68GliB/+8Ifu9ddfj3ns6aefdr/4xS+MJnr8Nm7c6AoKCqzHMCXJ7du3L/rxnTt3XDAYdG+99Vb0sa+//toFAgH3xz/+0WDCx+Ob58E550pKStyLL75oMo+VlpYWJ8nV1NQ45/rv9fDN8+Bc6lwPKXEn1NnZqVOnTqmoqCjm8aKiIp04ccJoKhv19fXKzs5WXl6eXn31VV28eNF6JFMNDQ1qbm6OuTb8fr9mzpzZ764NSaqurlZmZqbGjx+vpUuXqqWlxXqkpAqHw5KkjIwMSf33evjmebgnFa6HlIjQ1atXdfv2bWVlZcU8npWVpebmZqOpHr8pU6Zo165d+uijj/TOO++oublZhYWFam1ttR7NzL3///392pCk4uJivffeezpy5Ii2bNmi2tpazZkzRx0dHdajJYVzTqWlpXr++eeVn58vqX9eD92dByl1rode9y7aPfnmj3ZwznV5rC8rLi6O/veECRM0bdo0jR07Vjt37lRpaanhZPb6+7UhSYsWLYr+d35+viZNmqTc3FwdPHhQCxcuNJwsOVauXKlPPvlE//jHP7o815+uh287D6lyPaTEndDIkSM1YMCALv+SaWlp6fIvnv5k+PDhmjBhgurr661HMXPvqwO5NroKhULKzc3tk9fHqlWrdODAAR09ejTmR7/0t+vh285Dd3rr9ZASERo8eLAmTpyoqqqqmMerqqpUWFhoNJW9jo4OnTt3TqFQyHoUM3l5eQoGgzHXRmdnp2pqavr1tSFJra2tampq6lPXh3NOK1eu1N69e3XkyBHl5eXFPN9frocHnYfu9NrrwfCLIjz561//6gYNGuTeffdd9+mnn7rVq1e74cOHu0uXLlmP9tisWbPGVVdXu4sXL7qTJ0+6F154waWlpfX5c9DW1ubq6upcXV2dk+S2bt3q6urq3Oeff+6cc+6tt95ygUDA7d271505c8YtXrzYhUIhF4lEjCdPrJ7OQ1tbm1uzZo07ceKEa2hocEePHnXTpk1z3/nOd/rUefj5z3/uAoGAq66udleuXIluN27ciO7TH66HB52HVLoeUiZCzjn3hz/8weXm5rrBgwe75557LubLEfuDRYsWuVAo5AYNGuSys7PdwoUL3dmzZ63HSrqjR486SV22kpIS59zdL8vduHGjCwaDzu/3uxkzZrgzZ87YDp0EPZ2HGzduuKKiIjdq1Cg3aNAgN2bMGFdSUuIaGxutx06o7n7/klxlZWV0n/5wPTzoPKTS9cCPcgAAmEmJ14QAAH0TEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGDm/znf4gnjv6/sAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(mnist_train.data[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3)\n",
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([60000])\n"
     ]
    }
   ],
   "source": [
    "print(mnist_train.targets[10])\n",
    "print(mnist_train.data.shape)\n",
    "print(mnist_train.targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,  18,\n",
       "          18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170, 253,\n",
       "         253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253, 253,\n",
       "         253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253, 253,\n",
       "         198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253, 205,\n",
       "          11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,  90,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253, 190,\n",
       "           2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190, 253,\n",
       "          70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35, 241,\n",
       "         225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  81,\n",
       "         240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39, 148,\n",
       "         229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221, 253,\n",
       "         253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253, 253,\n",
       "         253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253, 195,\n",
       "          80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,  11,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]],\n",
       "       dtype=torch.uint8)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_train.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([60000])\n",
      "784\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "x=mnist_train.data.float()/255  # 데이터 스케일 조정\n",
    "# print(x[0])\n",
    "y=mnist_train.targets\n",
    "#y[:10]\n",
    "\n",
    "print(x.size())\n",
    "print(y.size())\n",
    "x=x.view(x.size(0), -1)  # 입력데이터 모양 변경(2차원-> 1차원으로 변경)\n",
    "\n",
    "input_size=x.size(-1)  # 입력데이터 크기\n",
    "print(input_size)\n",
    "output_size=int(max(y))+1 # 출력데이터 크기\n",
    "print(output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000 12000 10000\n",
      "torch.Size([48000, 784]) torch.Size([12000, 784])\n",
      "torch.Size([48000]) torch.Size([12000])\n",
      "torch.Size([48000, 784])\n",
      "torch.Size([12000, 784])\n",
      "torch.Size([10000, 784])\n",
      "torch.Size([48000])\n",
      "torch.Size([12000])\n",
      "torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "# 훈련데이터(train)와 검증데이터(valid)로 분리\n",
    "\n",
    "ratio=[0.8, 0.2]\n",
    "train_cnt=int(x.size(0)*ratio[0])\n",
    "valid_cnt=int(x.size(0)*ratio[1])\n",
    "test_cnt=len(mnist_test.data)\n",
    "\n",
    "print(train_cnt, valid_cnt, test_cnt)\n",
    "cnts=[train_cnt, valid_cnt]\n",
    "\n",
    "indices=torch.randperm(x.size(0))\n",
    "x=torch.index_select(x, dim=0, index=indices)\n",
    "y=torch.index_select(y, dim=0, index=indices)\n",
    "#plot(x[3])\n",
    "#y[3]\n",
    "\n",
    "x1=list(x.split(cnts, dim=0))\n",
    "y1=list(y.split(cnts, dim=0))\n",
    "print(x1[0].shape, x1[1].shape)\n",
    "print(y1[0].shape, y1[1].shape)\n",
    "\n",
    "x1+=[(mnist_test.data.float()/255).view(test_cnt, -1)]\n",
    "y1+=[mnist_test.targets]\n",
    "\n",
    "for ii in x1:\n",
    "    print(ii.shape)\n",
    "\n",
    "for yi in y1:\n",
    "    print(yi.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=784, out_features=500, bias=True)\n",
       "  (1): LeakyReLU(negative_slope=0.01)\n",
       "  (2): Linear(in_features=500, out_features=400, bias=True)\n",
       "  (3): LeakyReLU(negative_slope=0.01)\n",
       "  (4): Linear(in_features=400, out_features=300, bias=True)\n",
       "  (5): LeakyReLU(negative_slope=0.01)\n",
       "  (6): Linear(in_features=300, out_features=200, bias=True)\n",
       "  (7): LeakyReLU(negative_slope=0.01)\n",
       "  (8): Linear(in_features=200, out_features=100, bias=True)\n",
       "  (9): LeakyReLU(negative_slope=0.01)\n",
       "  (10): Linear(in_features=100, out_features=50, bias=True)\n",
       "  (11): LeakyReLU(negative_slope=0.01)\n",
       "  (12): Linear(in_features=50, out_features=10, bias=True)\n",
       "  (13): Softmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=nn.Sequential(\n",
    "    nn.Linear(input_size, 500),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(500, 400),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(400, 300),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(300, 200),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(200, 100),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(100, 50),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(50, output_size),\n",
    "    nn.Softmax(dim=-1)\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "crit=nn.CrossEntropyLoss() #\n",
    "optimizer=optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "    device=torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=model.to(device)\n",
    "x2=[x_i.to(device) for x_i in x1]\n",
    "y2=[y_i.to(device) for y_i in y1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=1000\n",
    "batch_size=256\n",
    "print_interval=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "lowest_loss=np.inf  # 최소 비용값 저장\n",
    "bast_model=None\n",
    "\n",
    "early_stop=50\n",
    "lowest_epoch=np.inf  # 최소 비용값을 가지는 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0, 2, 9,  ..., 2, 9, 4]),\n",
       " tensor([8, 5, 8,  ..., 6, 3, 3]),\n",
       " tensor([7, 2, 1,  ..., 4, 5, 6])]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_history, valid_history=[],[]\n",
    "\n",
    "for i in range(epochs):\n",
    "    indices=torch.randperm(x2[0].size(0)).to(device)\n",
    "    x_=torch.index_select(x2[0], dim=0, index=indices)\n",
    "    y_=torch.index_select(y2[0], dim=0, index=indices)\n",
    "\n",
    "    x_=x_.split(batch_size, dim=0)\n",
    "    y_=x_.split(batch_size, dim=0)\n",
    "\n",
    "    train_loss, valid_loss=0,0\n",
    "    y_hat=[]\n",
    "\n",
    "    for x_i, y_i in zip(x_, y_):\n",
    "        y_hat_i=model(x_i)\n",
    "        loss=crit(y_hat_i, y_i.squeeze())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss+=float(loss)\n",
    "    \n",
    "    train_loss=train_loss/len(x_) # len(x_)=4800/256\n",
    "\n",
    "    with torch.no_grad(): #기울기 미분을 하지 않는 다는 뜻\n",
    "        x_=x2[1].split(batch_size, dim=0)\n",
    "        y_=y2[1].split(batch_size, dim=0)\n",
    "        valid_loss=0\n",
    "\n",
    "        for x_i, y_i in zip(x_, y_):\n",
    "            y_hat_i=model(x_i)\n",
    "            loss=crit(y_hat_i, y_i)\n",
    "            valid_loss+=float(loss)\n",
    "\n",
    "            y_hat+=[y_hat_i]\n",
    "\n",
    "    valid_loss=valid_loss/len(x_i)\n",
    "\n",
    "    train_history+=[train_loss]\n",
    "    valid_history+=[valid_loss]\n",
    "\n",
    "    if (i+1) % print_interval==0:\n",
    "        print(i, train_loss, valid_loss, lowest_loss)\n",
    "\n",
    "    if valid_loss <=lowest_loss:\n",
    "        lowest_loss=valid_loss\n",
    "        lowest_epoch=i\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
