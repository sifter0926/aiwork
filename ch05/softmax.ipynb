{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0900, 0.2447, 0.6652])\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "z=torch.FloatTensor([1,2,3])\n",
    "y_hat=F.softmax(z, dim=0)\n",
    "print(y_hat)\n",
    "print(y_hat.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3395, 0.0990, 0.7017, 0.6098, 0.9200],\n",
      "        [0.4735, 0.3662, 0.4852, 0.6101, 0.7263],\n",
      "        [0.5908, 0.8600, 0.6470, 0.4912, 0.0135]], requires_grad=True)\n",
      "tensor([[0.1582, 0.1244, 0.2273, 0.2073, 0.2827],\n",
      "        [0.1871, 0.1681, 0.1893, 0.2145, 0.2410],\n",
      "        [0.2069, 0.2708, 0.2189, 0.1873, 0.1162]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000], grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "z=torch.rand(3, 5, requires_grad=True)\n",
    "print(z)\n",
    "y_hat=F.softmax(z, dim=1)\n",
    "print(y_hat)\n",
    "print(y_hat.sum(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 4])\n",
      "tensor([[0.1582, 0.1244, 0.2273, 0.2073, 0.2827],\n",
      "        [0.1871, 0.1681, 0.1893, 0.2145, 0.2410],\n",
      "        [0.2069, 0.2708, 0.2189, 0.1873, 0.1162]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n",
      "tensor([[0],\n",
      "        [1],\n",
      "        [4]])\n",
      "tensor([[1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "y=torch.randint(5,(3,)).long()\n",
    "print(y)\n",
    "print(y_hat)\n",
    "y_one_hot=torch.zeros_like(y_hat)\n",
    "print(y_one_hot)\n",
    "print(y.unsqueeze(1))\n",
    "y_one_hot.scatter_(1,y.unsqueeze(1),1)\n",
    "print(y_one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "x_data=[[1,2,1,1],\n",
    "        [2,1,3,2],\n",
    "        [3,1,3,4],\n",
    "        [4,1,5,5],\n",
    "        [1,7,5,5],\n",
    "        [1,2,5,6],\n",
    "        [1,6,6,6],\n",
    "        [1,7,7,7]]\n",
    "y_data=[2,2,2,1,1,1,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4])\n",
      "torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "x_train=torch.FloatTensor(x_data)\n",
    "y_train=torch.LongTensor(y_data)\n",
    "print(x_train.size())\n",
    "print(y_train.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "y_one_hot=torch.zeros(8,3)\n",
    "print(y_one_hot)\n",
    "y_one_hot.scatter_(1, y_train.unsqueeze(1),1)\n",
    "print(y_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], requires_grad=True)\n",
      "tensor([[0., 0., 0.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "w=torch.zeros((4,3), requires_grad=True)\n",
    "b=torch.zeros((1,3), requires_grad=True)\n",
    "print(w)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=optim.SGD([w,b], lr=0.1)\n",
    "epochs=10001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.0986123085021973\n",
      "100 0.7041995525360107\n",
      "200 0.6229996085166931\n",
      "300 0.5657169222831726\n",
      "400 0.5152913331985474\n",
      "500 0.46766167879104614\n",
      "600 0.4212779700756073\n",
      "700 0.3754016160964966\n",
      "800 0.3297654986381531\n",
      "900 0.2850721478462219\n",
      "1000 0.2481546849012375\n",
      "1100 0.23267611861228943\n",
      "1200 0.22139869630336761\n",
      "1300 0.21112915873527527\n",
      "1400 0.20173649489879608\n",
      "1500 0.1931133270263672\n",
      "1600 0.18516966700553894\n",
      "1700 0.1778293251991272\n",
      "1800 0.17102724313735962\n",
      "1900 0.16470739245414734\n",
      "2000 0.15882128477096558\n",
      "2100 0.15332657098770142\n",
      "2200 0.14818626642227173\n",
      "2300 0.14336799085140228\n",
      "2400 0.1388428956270218\n",
      "2500 0.13458555936813354\n",
      "2600 0.13057351112365723\n",
      "2700 0.12678645551204681\n",
      "2800 0.12320639193058014\n",
      "2900 0.1198171004652977\n",
      "3000 0.11660401523113251\n",
      "3100 0.11355391144752502\n",
      "3200 0.11065512150526047\n",
      "3300 0.10789669305086136\n",
      "3400 0.10526886582374573\n",
      "3500 0.10276280343532562\n",
      "3600 0.10037018358707428\n",
      "3700 0.09808389842510223\n",
      "3800 0.09589694440364838\n",
      "3900 0.0938030406832695\n",
      "4000 0.09179650247097015\n",
      "4100 0.08987218141555786\n",
      "4200 0.0880250483751297\n",
      "4300 0.08625059574842453\n",
      "4400 0.08454479277133942\n",
      "4500 0.08290377259254456\n",
      "4600 0.08132387697696686\n",
      "4700 0.07980184257030487\n",
      "4800 0.07833458483219147\n",
      "4900 0.07691922038793564\n",
      "5000 0.07555314153432846\n",
      "5100 0.07423384487628937\n",
      "5200 0.07295893132686615\n",
      "5300 0.07172621786594391\n",
      "5400 0.0705336406826973\n",
      "5500 0.06937950849533081\n",
      "5600 0.06826186180114746\n",
      "5700 0.06717892736196518\n",
      "5800 0.06612920761108398\n",
      "5900 0.06511135399341583\n",
      "6000 0.06412370502948761\n",
      "6100 0.06316513568162918\n",
      "6200 0.06223434954881668\n",
      "6300 0.06133010610938072\n",
      "6400 0.06045131757855415\n",
      "6500 0.05959698185324669\n",
      "6600 0.05876614898443222\n",
      "6700 0.057957716286182404\n",
      "6800 0.05717100948095322\n",
      "6900 0.05640484765172005\n",
      "7000 0.055658817291259766\n",
      "7100 0.054931916296482086\n",
      "7200 0.054223500192165375\n",
      "7300 0.05353277921676636\n",
      "7400 0.052859317511320114\n",
      "7500 0.052202221006155014\n",
      "7600 0.0515611357986927\n",
      "7700 0.05093526840209961\n",
      "7800 0.05032427981495857\n",
      "7900 0.049727585166692734\n",
      "8000 0.04914465174078941\n",
      "8100 0.04857509210705757\n",
      "8200 0.04801838472485542\n",
      "8300 0.04747416824102402\n",
      "8400 0.04694193974137306\n",
      "8500 0.046421267092227936\n",
      "8600 0.04591197520494461\n",
      "8700 0.045413583517074585\n",
      "8800 0.04492576792836189\n",
      "8900 0.04444824904203415\n",
      "9000 0.04398060962557793\n",
      "9100 0.04352254047989845\n",
      "9200 0.043073851615190506\n",
      "9300 0.042634181678295135\n",
      "9400 0.04220336675643921\n",
      "9500 0.0417809821665287\n",
      "9600 0.04136691242456436\n",
      "9700 0.04096090421080589\n",
      "9800 0.04056260362267494\n",
      "9900 0.04017195850610733\n",
      "10000 0.039788685739040375\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    y_hat=F.softmax(x_train.matmul(w)+b, dim=1)\n",
    "    cost=(y_one_hot* -torch.log(y_hat)).sum(dim=1).mean()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch%100==0:\n",
    "        print(epoch, cost.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7.9508e-11, 6.5690e-06, 9.9999e-01],\n",
      "        [1.7811e-04, 1.9474e-02, 9.8035e-01],\n",
      "        [1.1670e-13, 4.1809e-02, 9.5819e-01],\n",
      "        [6.1379e-10, 9.6248e-01, 3.7520e-02],\n",
      "        [7.2622e-02, 9.2453e-01, 2.8516e-03],\n",
      "        [3.8537e-02, 9.6146e-01, 7.0804e-08],\n",
      "        [9.1230e-01, 8.7705e-02, 8.1008e-08],\n",
      "        [9.9212e-01, 7.8797e-03, 5.7659e-11]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "y_hat=F.softmax(x_train.matmul(w)+b, dim=1)\n",
    "print(y_hat)\n",
    "print(y_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for y in y_hat:\n",
    "    print(y.argmax().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.datasets as datasets\n",
    "iris=datasets.load_iris()\n",
    "iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([150, 4])\n",
      "torch.Size([150])\n"
     ]
    }
   ],
   "source": [
    "x_train=torch.FloatTensor(iris.data)\n",
    "y_train=torch.LongTensor(iris.target)\n",
    "print(x_train.size())\n",
    "print(y_train.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=nn.Linear(4,3)\n",
    "optimizer=optim.SGD(model.parameters(), lr=0.1)\n",
    "epochs=10001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Cost: 1.7532501220703125\n",
      "Epoch: 100 Cost: 0.4651300609111786\n",
      "Epoch: 200 Cost: 0.2666434347629547\n",
      "Epoch: 300 Cost: 0.22042623162269592\n",
      "Epoch: 400 Cost: 0.19214804470539093\n",
      "Epoch: 500 Cost: 0.1727110594511032\n",
      "Epoch: 600 Cost: 0.15846771001815796\n",
      "Epoch: 700 Cost: 0.1475398689508438\n",
      "Epoch: 800 Cost: 0.1388620287179947\n",
      "Epoch: 900 Cost: 0.13178418576717377\n",
      "Epoch: 1000 Cost: 0.12588708102703094\n",
      "Epoch: 1100 Cost: 0.12088768184185028\n",
      "Epoch: 1200 Cost: 0.11658785492181778\n",
      "Epoch: 1300 Cost: 0.1128445565700531\n",
      "Epoch: 1400 Cost: 0.1095518246293068\n",
      "Epoch: 1500 Cost: 0.10662936419248581\n",
      "Epoch: 1600 Cost: 0.10401521623134613\n",
      "Epoch: 1700 Cost: 0.10166074335575104\n",
      "Epoch: 1800 Cost: 0.09952720999717712\n",
      "Epoch: 1900 Cost: 0.0975833311676979\n",
      "Epoch: 2000 Cost: 0.0958036258816719\n",
      "Epoch: 2100 Cost: 0.09416702389717102\n",
      "Epoch: 2200 Cost: 0.09265591949224472\n",
      "Epoch: 2300 Cost: 0.09125566482543945\n",
      "Epoch: 2400 Cost: 0.08995378017425537\n",
      "Epoch: 2500 Cost: 0.08873960375785828\n",
      "Epoch: 2600 Cost: 0.08760404586791992\n",
      "Epoch: 2700 Cost: 0.08653924614191055\n",
      "Epoch: 2800 Cost: 0.08553832024335861\n",
      "Epoch: 2900 Cost: 0.08459535241127014\n",
      "Epoch: 3000 Cost: 0.08370509743690491\n",
      "Epoch: 3100 Cost: 0.0828629657626152\n",
      "Epoch: 3200 Cost: 0.08206485956907272\n",
      "Epoch: 3300 Cost: 0.08130716532468796\n",
      "Epoch: 3400 Cost: 0.08058667927980423\n",
      "Epoch: 3500 Cost: 0.07990051805973053\n",
      "Epoch: 3600 Cost: 0.07924610376358032\n",
      "Epoch: 3700 Cost: 0.07862108200788498\n",
      "Epoch: 3800 Cost: 0.07802338153123856\n",
      "Epoch: 3900 Cost: 0.07745108753442764\n",
      "Epoch: 4000 Cost: 0.07690248638391495\n",
      "Epoch: 4100 Cost: 0.07637601345777512\n",
      "Epoch: 4200 Cost: 0.07587026059627533\n",
      "Epoch: 4300 Cost: 0.07538387924432755\n",
      "Epoch: 4400 Cost: 0.07491568475961685\n",
      "Epoch: 4500 Cost: 0.07446462661027908\n",
      "Epoch: 4600 Cost: 0.07402963936328888\n",
      "Epoch: 4700 Cost: 0.07360982894897461\n",
      "Epoch: 4800 Cost: 0.07320431619882584\n",
      "Epoch: 4900 Cost: 0.07281231880187988\n",
      "Epoch: 5000 Cost: 0.07243312150239944\n",
      "Epoch: 5100 Cost: 0.0720660537481308\n",
      "Epoch: 5200 Cost: 0.07171044498682022\n",
      "Epoch: 5300 Cost: 0.07136572152376175\n",
      "Epoch: 5400 Cost: 0.07103133946657181\n",
      "Epoch: 5500 Cost: 0.0707068219780922\n",
      "Epoch: 5600 Cost: 0.07039165496826172\n",
      "Epoch: 5700 Cost: 0.07008539885282516\n",
      "Epoch: 5800 Cost: 0.0697876363992691\n",
      "Epoch: 5900 Cost: 0.06949800997972488\n",
      "Epoch: 6000 Cost: 0.06921611726284027\n",
      "Epoch: 6100 Cost: 0.0689416378736496\n",
      "Epoch: 6200 Cost: 0.068674236536026\n",
      "Epoch: 6300 Cost: 0.0684136375784874\n",
      "Epoch: 6400 Cost: 0.06815952062606812\n",
      "Epoch: 6500 Cost: 0.06791161745786667\n",
      "Epoch: 6600 Cost: 0.06766971945762634\n",
      "Epoch: 6700 Cost: 0.06743352115154266\n",
      "Epoch: 6800 Cost: 0.0672028660774231\n",
      "Epoch: 6900 Cost: 0.06697745621204376\n",
      "Epoch: 7000 Cost: 0.06675714999437332\n",
      "Epoch: 7100 Cost: 0.06654174625873566\n",
      "Epoch: 7200 Cost: 0.06633106619119644\n",
      "Epoch: 7300 Cost: 0.06612490117549896\n",
      "Epoch: 7400 Cost: 0.06592313200235367\n",
      "Epoch: 7500 Cost: 0.06572557240724564\n",
      "Epoch: 7600 Cost: 0.06553209573030472\n",
      "Epoch: 7700 Cost: 0.06534253805875778\n",
      "Epoch: 7800 Cost: 0.06515678763389587\n",
      "Epoch: 7900 Cost: 0.06497468799352646\n",
      "Epoch: 8000 Cost: 0.06479613482952118\n",
      "Epoch: 8100 Cost: 0.06462102383375168\n",
      "Epoch: 8200 Cost: 0.06444922834634781\n",
      "Epoch: 8300 Cost: 0.06428063660860062\n",
      "Epoch: 8400 Cost: 0.06411515176296234\n",
      "Epoch: 8500 Cost: 0.06395266950130463\n",
      "Epoch: 8600 Cost: 0.0637931227684021\n",
      "Epoch: 8700 Cost: 0.0636363998055458\n",
      "Epoch: 8800 Cost: 0.06348240375518799\n",
      "Epoch: 8900 Cost: 0.06333109736442566\n",
      "Epoch: 9000 Cost: 0.06318233162164688\n",
      "Epoch: 9100 Cost: 0.06303610652685165\n",
      "Epoch: 9200 Cost: 0.06289231032133102\n",
      "Epoch: 9300 Cost: 0.06275088340044022\n",
      "Epoch: 9400 Cost: 0.06261174380779266\n",
      "Epoch: 9500 Cost: 0.06247483566403389\n",
      "Epoch: 9600 Cost: 0.06234011799097061\n",
      "Epoch: 9700 Cost: 0.06220751628279686\n",
      "Epoch: 9800 Cost: 0.06207696348428726\n",
      "Epoch: 9900 Cost: 0.06194840744137764\n",
      "Epoch: 10000 Cost: 0.06182181090116501\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    y_hat=model(x_train)\n",
    "    cost=F.cross_entropy(y_hat, y_train)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch%100==0:\n",
    "        print('Epoch:', epoch,'Cost:', cost.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 tensor(147.)\n",
      "tensor(0.9800)\n"
     ]
    }
   ],
   "source": [
    "predict=model(x_train)\n",
    "#print(predict)\n",
    "\n",
    "accuracys=[]\n",
    "\n",
    "for i in range(len(predict)):\n",
    "    accuracys.append(y_train[i]==predict[i].argmax())\n",
    "\n",
    "print(len(accuracys), torch.FloatTensor(accuracys).sum())\n",
    "print(torch.FloatTensor(accuracys).sum()/len(accuracys))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
