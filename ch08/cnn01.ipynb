{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 28, 28])\n",
      "tensor([[[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "           0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "           0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "           0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "           0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "           0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "           0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "           0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "           0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "           0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "           0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "           0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "           0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "           0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "           0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "           0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "           0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "           0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "           0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "           0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "           0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "           0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "           0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "           0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "           0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "           0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "           0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "           0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "           0., 0., 0., 0., 0.]]]])\n"
     ]
    }
   ],
   "source": [
    "input=torch.Tensor(1,1,28,28) #배치크기(한번에 로딩하는 이미지 수), 채널, 높이, 너비\n",
    "print(input.size())\n",
    "print(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n"
     ]
    }
   ],
   "source": [
    "conv1=nn.Conv2d(1, 32, 3, padding=1) \n",
    "# Conv2d(입력 채널 수, 출력 채널 수, kernal_size(필터의 크기), stride=1, padding=1)\n",
    "print(conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n"
     ]
    }
   ],
   "source": [
    "conv2=nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "print(conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n"
     ]
    }
   ],
   "source": [
    "pool=nn.MaxPool2d(2)\n",
    "print(pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 28, 28])\n",
      "torch.Size([1, 32, 14, 14])\n"
     ]
    }
   ],
   "source": [
    "out1=conv1(input)\n",
    "out2=pool(out1)\n",
    "print(out1.size())\n",
    "print(out2.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 14, 14])\n",
      "torch.Size([1, 64, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "out3=conv2(out2)\n",
    "out4=pool(out3)\n",
    "print(out3.size())\n",
    "print(out4.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3136])\n"
     ]
    }
   ],
   "source": [
    "out=out4.view(out4.size(0), -1)\n",
    "print(out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10])\n",
      "tensor([[-0.0417, -0.0051,  0.0823, -0.0831,  0.0042, -0.0126,  0.1115,  0.1041,\n",
      "          0.0233,  0.0103]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "fc=nn.Linear(3136, 10)\n",
    "outf=fc(out)\n",
    "print(outf.size())\n",
    "print(outf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "torch.manual_seed(777)\n",
    "\n",
    "if device=='cuda':\n",
    "    torch.cuda.manual_seed_all(777)\n",
    "\n",
    "# device=''\n",
    "# if torch.cuda.is_available:\n",
    "#     device='cuda'\n",
    "# else:\n",
    "#     device='cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "learing_rate=0.001\n",
    "epochs=15\n",
    "batch_size=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train=dsets.MNIST(root='MNIST_data',\n",
    "                        train=True,\n",
    "                        transform=transforms.ToTensor(),\n",
    "                        download=True)\n",
    "mnist_test=dsets.MNIST(root='MNIST_data',\n",
    "                        train=False,\n",
    "                        transform=transforms.ToTensor(),\n",
    "                        download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: MNIST_data\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n",
      "Dataset MNIST\n",
      "    Number of datapoints: 10000\n",
      "    Root location: MNIST_data\n",
      "    Split: Test\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n"
     ]
    }
   ],
   "source": [
    "print(mnist_train)\n",
    "print(mnist_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=DataLoader(dataset=mnist_train,\n",
    "                       batch_size=batch_size,\n",
    "                       shuffle=True,\n",
    "                       drop_last=False)\n",
    "\n",
    "test_loader=DataLoader(dataset=mnist_test,\n",
    "                       batch_size=batch_size,\n",
    "                       shuffle=True,\n",
    "                       drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "for X, Y in train_loader:\n",
    "    print(X.size())\n",
    "    print(Y.size())\n",
    "    break\n",
    "for Y,Y in test_loader:\n",
    "    print(X.size())\n",
    "    print(Y.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        #conv layer1\n",
    "        #image in shape(100, 1, 28, 28)\n",
    "        # conv -> (?, 32, 28, 28)\n",
    "        # pool ->(?, 32, 14,14)\n",
    "\n",
    "        self.layer1=nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        #conv layer1\n",
    "        #image in shape(?, 32, 14, 14)\n",
    "        # conv -> (?, 64, 14, 14)\n",
    "        # pool ->(?, 64, 7, 7)\n",
    "        self.layer2=nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        #완전 연결층 (100,64*7*7)\n",
    "        self.fc=nn.Linear(64*7*7, 10, bias=True)\n",
    "        #완전 연결층 한정으로 가중치 초기화\n",
    "        nn.init.xavier_uniform_(self.fc.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "            out=self.layer1(x)\n",
    "            out=self.layer2(out)\n",
    "            out=out.view(out.size(0),-1)\n",
    "            out=self.fc(out)\n",
    "            return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=CNN().to(device)\n",
    "criterion=nn.CrossEntropyLoss().to(device)\n",
    "optimizer=torch.optim.Adam(model.parameters(), lr=learing_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc): Linear(in_features=3136, out_features=10, bias=True)\n",
      ")\n",
      "[Parameter containing:\n",
      "tensor([[[[-0.2605,  0.0809,  0.1567],\n",
      "          [ 0.3265,  0.2777, -0.1169],\n",
      "          [ 0.2477,  0.2583,  0.2690]]],\n",
      "\n",
      "\n",
      "        [[[-0.1864, -0.0669, -0.1780],\n",
      "          [ 0.2941,  0.2786,  0.2635],\n",
      "          [-0.0440, -0.2318, -0.1231]]],\n",
      "\n",
      "\n",
      "        [[[-0.0819,  0.0778,  0.0237],\n",
      "          [ 0.3314, -0.0815,  0.3027],\n",
      "          [ 0.2188,  0.0973,  0.0363]]],\n",
      "\n",
      "\n",
      "        [[[-0.0865, -0.2869, -0.0754],\n",
      "          [ 0.1529,  0.2711, -0.3294],\n",
      "          [-0.3166, -0.0336, -0.1902]]],\n",
      "\n",
      "\n",
      "        [[[-0.0712,  0.0088,  0.3326],\n",
      "          [-0.2331, -0.1208,  0.2693],\n",
      "          [ 0.1990,  0.2356, -0.2919]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1017,  0.3330,  0.0286],\n",
      "          [ 0.1301, -0.2682, -0.1230],\n",
      "          [-0.2192,  0.1566,  0.2923]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1307, -0.2792, -0.0994],\n",
      "          [ 0.0590, -0.0618, -0.1577],\n",
      "          [-0.2207, -0.3056, -0.1023]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3126, -0.2702, -0.1665],\n",
      "          [-0.0333, -0.1584,  0.1623],\n",
      "          [-0.2806,  0.1187,  0.2501]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2609, -0.2991,  0.1036],\n",
      "          [ 0.3308,  0.2615,  0.2570],\n",
      "          [-0.2950, -0.2729,  0.2093]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3139,  0.3328,  0.2042],\n",
      "          [ 0.2598,  0.2591,  0.1484],\n",
      "          [ 0.1641,  0.0026, -0.2068]]],\n",
      "\n",
      "\n",
      "        [[[-0.0575, -0.0365,  0.1716],\n",
      "          [ 0.1573, -0.2550, -0.3291],\n",
      "          [-0.2821,  0.0772,  0.2648]]],\n",
      "\n",
      "\n",
      "        [[[-0.0712, -0.1311,  0.1894],\n",
      "          [-0.2725, -0.1364, -0.1009],\n",
      "          [ 0.0979,  0.1141, -0.3041]]],\n",
      "\n",
      "\n",
      "        [[[-0.2175,  0.2023,  0.3226],\n",
      "          [ 0.1601,  0.2816, -0.1759],\n",
      "          [-0.2123,  0.3159,  0.2259]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2425, -0.1316,  0.1308],\n",
      "          [-0.3323, -0.1549,  0.0843],\n",
      "          [ 0.2474, -0.1425,  0.1241]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3190, -0.2352,  0.1003],\n",
      "          [ 0.1888, -0.2161,  0.2096],\n",
      "          [-0.3160, -0.3064,  0.0479]]],\n",
      "\n",
      "\n",
      "        [[[-0.1659, -0.2786, -0.0599],\n",
      "          [-0.1272, -0.1172,  0.3289],\n",
      "          [-0.1283, -0.1854,  0.1314]]],\n",
      "\n",
      "\n",
      "        [[[-0.0683, -0.2337, -0.0479],\n",
      "          [ 0.0542, -0.0827,  0.3231],\n",
      "          [ 0.1332, -0.1471,  0.0259]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1739, -0.1047, -0.3154],\n",
      "          [ 0.1016, -0.1084,  0.2610],\n",
      "          [ 0.0854, -0.0756,  0.2779]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1631,  0.2344,  0.1149],\n",
      "          [ 0.0981,  0.0963, -0.1684],\n",
      "          [ 0.0712, -0.2663, -0.2805]]],\n",
      "\n",
      "\n",
      "        [[[-0.2322,  0.2582,  0.2852],\n",
      "          [-0.1024,  0.2572,  0.3126],\n",
      "          [ 0.3281, -0.2638, -0.0819]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1029,  0.2124,  0.2295],\n",
      "          [ 0.1353, -0.3051,  0.0572],\n",
      "          [-0.2478,  0.1103,  0.0163]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2067, -0.0526,  0.0688],\n",
      "          [ 0.2928,  0.2072, -0.3318],\n",
      "          [-0.2151,  0.1554, -0.2487]]],\n",
      "\n",
      "\n",
      "        [[[-0.1549,  0.2958, -0.2790],\n",
      "          [ 0.0166, -0.2162, -0.0381],\n",
      "          [ 0.2679, -0.2823, -0.0911]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0908, -0.2158,  0.2299],\n",
      "          [-0.1895,  0.1891, -0.2789],\n",
      "          [ 0.2379,  0.2124,  0.0350]]],\n",
      "\n",
      "\n",
      "        [[[-0.0709,  0.0279, -0.3213],\n",
      "          [-0.1476, -0.2718, -0.1785],\n",
      "          [-0.3086,  0.2947,  0.0818]]],\n",
      "\n",
      "\n",
      "        [[[-0.1109, -0.2405, -0.0977],\n",
      "          [-0.0040, -0.1272,  0.1398],\n",
      "          [-0.1941, -0.0447,  0.2424]]],\n",
      "\n",
      "\n",
      "        [[[-0.1583,  0.0174, -0.1170],\n",
      "          [ 0.3143, -0.2018, -0.1207],\n",
      "          [ 0.3130,  0.3164,  0.0551]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0522, -0.0805, -0.2035],\n",
      "          [-0.0993, -0.2143, -0.1273],\n",
      "          [ 0.2047, -0.0724,  0.2597]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1627,  0.0517, -0.2606],\n",
      "          [ 0.3025, -0.3060,  0.1799],\n",
      "          [-0.0455,  0.1448, -0.3253]]],\n",
      "\n",
      "\n",
      "        [[[-0.0381,  0.1860,  0.0175],\n",
      "          [ 0.2193, -0.0417,  0.0586],\n",
      "          [ 0.3148, -0.0609, -0.1054]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1091,  0.3042, -0.2802],\n",
      "          [ 0.2080,  0.2653, -0.3054],\n",
      "          [ 0.1423, -0.0371, -0.0164]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2944, -0.3295,  0.1966],\n",
      "          [ 0.2504,  0.2872, -0.1087],\n",
      "          [-0.2173,  0.1207,  0.3144]]]], requires_grad=True), Parameter containing:\n",
      "tensor([ 0.3254, -0.1211, -0.2152,  0.0979, -0.2332, -0.2147,  0.0843, -0.1669,\n",
      "         0.1928, -0.0472, -0.0040, -0.1596,  0.2521,  0.2944, -0.1679,  0.3218,\n",
      "        -0.2893, -0.1462,  0.2682,  0.2949, -0.2832, -0.1837, -0.2611,  0.3331,\n",
      "        -0.1032,  0.2296,  0.1684, -0.0872,  0.2135, -0.2261,  0.1232, -0.2058],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[[[-5.1586e-02, -4.8732e-02,  6.4627e-04],\n",
      "          [ 1.4231e-02,  3.6066e-02, -2.3979e-02],\n",
      "          [-3.8486e-02, -6.7389e-03,  4.0566e-02]],\n",
      "\n",
      "         [[-4.5120e-02, -3.1343e-02,  1.0106e-02],\n",
      "          [ 5.2540e-02,  5.5715e-02,  3.4432e-02],\n",
      "          [-5.5375e-02, -4.9832e-02, -2.1334e-02]],\n",
      "\n",
      "         [[-3.0562e-02, -3.8565e-02, -3.4564e-02],\n",
      "          [-3.8623e-02, -3.1506e-02, -1.3110e-02],\n",
      "          [ 5.7957e-02,  4.2075e-02,  2.9108e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.3226e-02,  1.1358e-02,  2.9103e-02],\n",
      "          [ 5.6544e-02,  5.2464e-02,  5.3189e-02],\n",
      "          [-2.0630e-02,  4.7062e-02,  4.1168e-02]],\n",
      "\n",
      "         [[ 7.1651e-03, -3.5697e-02, -3.8631e-02],\n",
      "          [ 2.5947e-02, -7.0936e-03, -3.9856e-02],\n",
      "          [ 3.5475e-03, -9.0767e-04, -1.8672e-02]],\n",
      "\n",
      "         [[ 1.2161e-02, -2.8706e-02,  7.1298e-05],\n",
      "          [-1.0085e-02,  5.5975e-02,  3.7970e-02],\n",
      "          [ 4.9600e-02,  1.8733e-02, -1.6530e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 5.4355e-02, -4.1842e-02,  5.5005e-03],\n",
      "          [ 5.2895e-02,  1.5928e-02,  3.0741e-02],\n",
      "          [-5.0070e-02, -9.1895e-04,  3.1773e-02]],\n",
      "\n",
      "         [[ 2.0430e-02, -2.1862e-02,  3.9692e-03],\n",
      "          [ 4.4785e-03, -4.8602e-02, -3.3872e-02],\n",
      "          [ 2.9355e-02, -5.7644e-02, -5.4342e-02]],\n",
      "\n",
      "         [[-3.3508e-02,  2.2918e-02,  5.6339e-02],\n",
      "          [ 5.0618e-03, -1.3339e-02,  2.9411e-02],\n",
      "          [-9.5659e-03,  4.2442e-02, -1.9215e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.5226e-02,  1.0174e-02,  5.1461e-03],\n",
      "          [-3.4455e-03,  4.6293e-03,  2.4002e-02],\n",
      "          [-2.4523e-02, -8.4578e-03,  5.8371e-02]],\n",
      "\n",
      "         [[-2.7321e-03,  5.4280e-02,  2.5768e-02],\n",
      "          [ 4.2208e-02,  1.6530e-02,  1.5966e-03],\n",
      "          [ 3.4183e-02, -3.3118e-03, -4.0643e-02]],\n",
      "\n",
      "         [[-9.2249e-03, -3.6404e-02,  5.9482e-03],\n",
      "          [ 3.3908e-02,  4.5842e-02,  2.3027e-02],\n",
      "          [ 1.3570e-02, -3.7284e-02,  5.7055e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.3619e-02, -5.7537e-03, -4.7921e-02],\n",
      "          [ 9.5729e-03, -4.2733e-02, -1.0386e-02],\n",
      "          [ 3.3457e-02, -5.1192e-02,  3.9368e-02]],\n",
      "\n",
      "         [[ 7.8398e-03, -3.7882e-02, -1.5958e-03],\n",
      "          [ 2.5784e-02, -2.4045e-02,  9.1193e-03],\n",
      "          [ 3.2226e-03, -2.9877e-02,  5.1220e-02]],\n",
      "\n",
      "         [[ 5.3858e-02, -6.1496e-03, -3.9379e-02],\n",
      "          [-5.1623e-02,  1.6140e-03, -2.7024e-02],\n",
      "          [ 5.4180e-02, -3.3558e-02, -2.7977e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.1357e-02,  1.4019e-02,  4.5556e-02],\n",
      "          [ 3.4528e-02, -4.0805e-02,  4.2186e-02],\n",
      "          [-1.1116e-02,  1.7047e-02, -8.4650e-03]],\n",
      "\n",
      "         [[-7.9351e-03,  3.9733e-02, -5.7479e-02],\n",
      "          [ 3.7370e-02,  5.7753e-03, -2.5823e-02],\n",
      "          [-2.2613e-02, -5.1069e-02,  2.7186e-03]],\n",
      "\n",
      "         [[ 4.5492e-03, -5.3775e-02, -2.2947e-02],\n",
      "          [-9.2861e-03, -4.4556e-03, -2.4902e-02],\n",
      "          [ 1.5346e-02, -4.6155e-03,  1.1982e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 2.3308e-02, -3.9318e-02, -7.4283e-03],\n",
      "          [-2.5869e-02, -3.5656e-02,  4.3770e-02],\n",
      "          [-5.6263e-02, -4.2173e-02, -3.6499e-02]],\n",
      "\n",
      "         [[-2.8303e-03,  2.7288e-02,  2.0480e-02],\n",
      "          [-5.8289e-02,  4.7222e-02,  3.2557e-02],\n",
      "          [-3.0055e-02, -3.4767e-02, -3.7779e-03]],\n",
      "\n",
      "         [[-5.0353e-02, -3.1079e-02, -3.6046e-02],\n",
      "          [-2.1264e-02,  2.3048e-02,  1.7941e-02],\n",
      "          [ 4.7607e-02, -3.6641e-02, -1.8767e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.7622e-02, -2.9623e-02,  4.5490e-03],\n",
      "          [-4.6237e-03,  3.7029e-02,  4.3639e-02],\n",
      "          [-5.3632e-03,  1.9998e-02, -2.8020e-02]],\n",
      "\n",
      "         [[-2.5361e-02,  1.0624e-02, -2.7822e-02],\n",
      "          [-5.6206e-02, -3.6909e-02, -3.3843e-03],\n",
      "          [-7.0817e-03,  9.7566e-03,  4.5682e-02]],\n",
      "\n",
      "         [[-2.2358e-02,  2.4131e-02, -7.7396e-03],\n",
      "          [ 2.9677e-02,  3.8895e-02, -2.8591e-03],\n",
      "          [ 4.4733e-02,  9.3349e-03,  5.1214e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.5944e-02, -3.5688e-02, -5.1782e-02],\n",
      "          [-5.5349e-02, -4.9713e-02,  2.8106e-02],\n",
      "          [ 5.8403e-02, -1.5495e-02,  8.2462e-04]],\n",
      "\n",
      "         [[-1.2758e-02, -1.6065e-02,  1.3197e-02],\n",
      "          [-3.5969e-02, -2.9321e-02,  2.7499e-02],\n",
      "          [-9.9744e-03, -5.5153e-02, -8.1942e-04]],\n",
      "\n",
      "         [[-4.9285e-02,  2.0259e-02, -4.8751e-02],\n",
      "          [-8.3447e-03, -1.7407e-02,  6.1567e-03],\n",
      "          [ 1.6313e-02,  1.5598e-02, -8.0492e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.0361e-02,  8.3139e-03, -5.0212e-02],\n",
      "          [-2.9574e-02,  1.6161e-02, -4.7635e-02],\n",
      "          [-7.5421e-03, -4.4661e-02,  2.4888e-02]],\n",
      "\n",
      "         [[ 5.5209e-02,  1.1294e-02, -2.1619e-02],\n",
      "          [ 1.3970e-02, -2.0111e-02,  3.4196e-02],\n",
      "          [ 6.3238e-03, -4.0969e-02, -5.4787e-03]],\n",
      "\n",
      "         [[-5.0925e-02, -2.0762e-02, -1.9791e-02],\n",
      "          [-1.6505e-02,  4.9085e-02,  4.4081e-02],\n",
      "          [ 3.5551e-02,  5.6658e-02,  3.5148e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 4.1301e-02,  3.2570e-02,  3.3009e-02],\n",
      "          [-3.8617e-03, -1.4578e-02,  1.1771e-02],\n",
      "          [ 4.1705e-02,  5.3813e-02, -2.4375e-02]],\n",
      "\n",
      "         [[-2.2218e-02,  5.1092e-02,  5.6829e-02],\n",
      "          [-1.6540e-02, -4.8412e-02,  3.3920e-02],\n",
      "          [ 1.5961e-02, -2.2125e-02, -3.8396e-02]],\n",
      "\n",
      "         [[ 2.6609e-02, -2.9097e-02,  8.9974e-03],\n",
      "          [ 2.1587e-02, -1.5003e-02,  4.8626e-02],\n",
      "          [-2.0691e-02, -3.4215e-02,  5.8862e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.1256e-03,  4.8085e-03,  2.0799e-02],\n",
      "          [ 8.4982e-03,  5.4266e-02,  2.6113e-02],\n",
      "          [-4.6040e-03, -1.6883e-02,  5.8851e-02]],\n",
      "\n",
      "         [[-9.8750e-03, -2.1988e-04, -6.7923e-03],\n",
      "          [ 1.3150e-02, -5.2041e-02,  1.9972e-02],\n",
      "          [-2.2218e-05, -5.7451e-03,  1.1867e-02]],\n",
      "\n",
      "         [[ 7.6336e-03, -3.8987e-02, -4.9990e-02],\n",
      "          [-1.5889e-02, -3.7517e-02,  1.8442e-02],\n",
      "          [-5.3677e-03, -3.4082e-02, -4.3258e-02]]]], requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0112, -0.0120, -0.0568,  0.0145,  0.0130, -0.0354,  0.0127,  0.0438,\n",
      "         0.0490, -0.0458,  0.0580, -0.0396, -0.0239,  0.0303, -0.0455,  0.0543,\n",
      "        -0.0111,  0.0474,  0.0034, -0.0288,  0.0372, -0.0520, -0.0179,  0.0147,\n",
      "        -0.0552, -0.0517, -0.0143,  0.0443, -0.0509, -0.0197,  0.0349,  0.0326,\n",
      "        -0.0404,  0.0377, -0.0393,  0.0113, -0.0002,  0.0141, -0.0121,  0.0033,\n",
      "        -0.0381,  0.0426, -0.0075, -0.0113, -0.0520, -0.0180,  0.0160, -0.0013,\n",
      "        -0.0245,  0.0408,  0.0022,  0.0491,  0.0560, -0.0440, -0.0016, -0.0501,\n",
      "        -0.0292, -0.0412, -0.0074, -0.0425, -0.0091,  0.0159, -0.0555,  0.0568],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0423,  0.0194, -0.0363,  ..., -0.0315, -0.0100, -0.0237],\n",
      "        [ 0.0072,  0.0114, -0.0109,  ...,  0.0324, -0.0275, -0.0204],\n",
      "        [ 0.0339,  0.0238, -0.0328,  ..., -0.0138, -0.0160,  0.0218],\n",
      "        ...,\n",
      "        [ 0.0012,  0.0176, -0.0133,  ..., -0.0298, -0.0390, -0.0155],\n",
      "        [-0.0402,  0.0232, -0.0255,  ...,  0.0027, -0.0003, -0.0045],\n",
      "        [-0.0073, -0.0350,  0.0306,  ..., -0.0334,  0.0117,  0.0116]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.0100,  0.0170,  0.0083, -0.0031, -0.0164,  0.0078, -0.0017,  0.0164,\n",
      "        -0.0104, -0.0085], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print(model)\n",
    "print(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "train_total_batch=len(train_loader)\n",
    "test_total_batch=len(test_loader)\n",
    "print(train_total_batch)\n",
    "print(test_total_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoc: 0 cost: tensor(0.2321, grad_fn=<AddBackward0>)\n",
      "Epoc: 1 cost: tensor(0.0651, grad_fn=<AddBackward0>)\n",
      "Epoc: 2 cost: tensor(0.0479, grad_fn=<AddBackward0>)\n",
      "Epoc: 3 cost: tensor(0.0380, grad_fn=<AddBackward0>)\n",
      "Epoc: 4 cost: tensor(0.0319, grad_fn=<AddBackward0>)\n",
      "Epoc: 5 cost: tensor(0.0269, grad_fn=<AddBackward0>)\n",
      "Epoc: 6 cost: tensor(0.0231, grad_fn=<AddBackward0>)\n",
      "Epoc: 7 cost: tensor(0.0190, grad_fn=<AddBackward0>)\n",
      "Epoc: 8 cost: tensor(0.0173, grad_fn=<AddBackward0>)\n",
      "Epoc: 9 cost: tensor(0.0133, grad_fn=<AddBackward0>)\n",
      "Epoc: 10 cost: tensor(0.0115, grad_fn=<AddBackward0>)\n",
      "Epoc: 11 cost: tensor(0.0102, grad_fn=<AddBackward0>)\n",
      "Epoc: 12 cost: tensor(0.0093, grad_fn=<AddBackward0>)\n",
      "Epoc: 13 cost: tensor(0.0085, grad_fn=<AddBackward0>)\n",
      "Epoc: 14 cost: tensor(0.0059, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    avg_cost=0\n",
    "\n",
    "    for X, Y in train_loader:\n",
    "        X=X.to(device)\n",
    "        Y=Y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        y_hat=model(X)\n",
    "        cost=criterion(y_hat, Y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_cost+=cost/train_total_batch\n",
    "    print('Epoc:', epoch, 'cost:', avg_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: tensor(99.1400)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    avg_accuracy=0\n",
    "\n",
    "    for X,Y in test_loader:\n",
    "        X=X.to(device)\n",
    "        Y=Y.to(device)\n",
    "        pred=model(X)\n",
    "        correct_prde=torch.argmax(pred, -1)==Y\n",
    "        accuracy=correct_prde.float().sum()\n",
    "        avg_accuracy+=accuracy\n",
    "    avg_accuracy=avg_accuracy/test_total_batch\n",
    "print('Accuracy:', avg_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
